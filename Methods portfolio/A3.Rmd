---
title: "A3"
author: "Sara"
date: "2022-11-02"
output: html_document
--- 
#open w8 and w10 for slides
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

setwd('.')

pacman::p_load(
  tidyverse,
  tidybayes,
  brms,
  bayesplot,
  dplyr,
  ggplot2,
  gridExtra,
  viridis,
  tidymodels,
)
```

# The assignment
The Machine Learning assignment has 3 main parts: First we create a skeptical and an informed simulation, based on the meta-analysis. Second we build and test our machine learning pipeline on the simulated data. Second we apply the pipeline to the empirical data.
The report for the exam, thus, consists of the answer to all the following prompts:
- Describe your machine learning pipeline. Produce a diagram of it to guide the reader (e.g. see Rybner et al 2022 Vocal markers of autism: Assessing the generalizability of ML models), and describe the different parts: data budgeting, data preprocessing, model choice and training, assessment of performance.
- Briefly justify and describe your use of simulated data, and results from the pipeline on them.
- Describe results from applying the ML pipeline to the empirical data and what can we learn from them.
Remember: plots are very very important to communicate your process and results.

## Part I - Simulating data
Use the meta-analysis reported in Parola et al (2020), create a simulated dataset with 100 matched pairs of schizophrenia and controls, each participant producing 10 repeated measures (10 trials with their speech recorded). for each of these "recordings" (data points) produce 10 acoustic measures: 6 from the meta-analysis, 4 with just random noise. Do the same for a baseline dataset including only 10 noise variables. Tip: see the slides for the code. 
```{r simulate data}
#W8 slide 12
#two participants 10 trials, population effect of 0.25 in cohens D, individual variation is 1, sample pair difference from population level pair::rnorm(1,0.25,1) = 0.6, the individual mean measures are then sc 0.3 and control 0.3

#slide 13 Schizophrenia mean: 0.21 |   Control mean:  -0.21
# TrialSD = 0.5 (the average variation between trials)
# Error = 0.2 (measurement error)
# 
# Schizophrenia <- rnorm(1, rnorm(1, 0.21, 0.5), 0.2) # repeat 10 times
# 
# Control <- rnorm(1, rnorm(1, -0.21, 0.5), 0.2) # repeat 10 times

set.seed(2022)

#W8 slide 14
SampleSize <- 100 #100 pairs
Trials <- 10 #10 trials per pair

## define effectsizes for MA and noise, Schizo compared to healthy control
MA_InformedEffectMean <- c(0.25, -0.55, -0.75, -1.26, 0.05, 1.89,0,0,0,0)

#make effect sizes for these 6 acostic variables

# Pitch mode: 0.25 (-0.72, 1.30)
# Pitch variability: -0.55 (-1.06, 0.09)
# Duration
# Speech rate: -0.75 (-1.51, 0.04)
# Proportion of spoken time: -1.26 (-2.26, 0.25)
# Pause number: 0.05 (-1.23, 1.13) 
# Pause length: 1.89(0.72,3.21)

Noise_SkepticEffectMean <- rep(0,10)

# define individual variability from population and across trials and measurement
IndividualSD <- 1
TrialSD <- 0.5
Error <- 0.2

## For each pair participants we need to identify the true effect size for each variable
for (i in seq(10)){
  temp_informed <- tibble(
    ID         = seq(SampleSize),
    TrueEffect = rnorm(SampleSize, MA_InformedEffectMean[i], IndividualSD),
    Variable   = paste0("v",i))
  temp_skeptic <- tibble(
    ID         = seq(SampleSize),
    TrueEffect = rnorm(SampleSize, Noise_SkepticEffectMean[i], IndividualSD),
    Variable   = paste0("v",i))
  if (i == 1){
    d_informed_true <- temp_informed
    d_skeptic_true <- temp_skeptic
  } else {
    d_informed_true <- rbind(d_informed_true,temp_informed)
    d_skeptic_true <- rbind(d_skeptic_true,temp_skeptic)
  }
}

#Create tibble with one row per trial
d_trial <- tibble(expand_grid(ID = seq(SampleSize), Trial = seq(Trials), Group = c("Schizophrenia","Control")))

d_informed <- merge(d_informed_true,d_trial)
d_skeptic <- merge(d_skeptic_true,d_trial)

for (i in seq(nrow(d_informed))){
  d_informed$measurement[i] <- ifelse(d_informed$Group[i]=="Schizophrenia",
                                      rnorm(1,rnorm(1,d_informed$TrueEffect[i]/2,TrialSD),Error),
                                      rnorm(1, rnorm(1, (-d_informed$TrueEffect[i]/2), TrialSD), Error)
                                      )
  d_skeptic$measurement[i] <- ifelse(d_skeptic$Group[i]=="Schizophrenia",
                                     rnorm(1,rnorm(1,d_skeptic$TrueEffect[i]/2,TrialSD),Error),
                                      rnorm(1, rnorm(1, (-d_skeptic$TrueEffect[i]/2), TrialSD), Error))
}
                                     
d_informed_wide <- d_informed %>% 
  mutate(TrueEffect = NULL) %>% 
  pivot_wider(names_from  = Variable,
              values_from = measurement)

d_skeptic_wide <- d_skeptic %>% 
  mutate(TrueEffect = NULL) %>% 
  pivot_wider(names_from  = Variable,
              values_from = measurement)

#reorder columns
df_informed_wide <- d_informed_wide[,c(1,2,3,4,11,12,5,13,7,10,6,8,9)]
df_skeptic_wide <- d_skeptic_wide[,c(1,2,3,4,11,12,5,13,7,10,6,8,9)]


#rename columns
# Pitch mode: 0.25 (-0.72, 1.30)
# Pitch variability: -0.55 (-1.06, 0.09)
# Duration
# Speech rate: -0.75 (-1.51, 0.04)
# Proportion of spoken time: -1.26 (-2.26, 0.25)
# Pause number: 0.05 (-1.23, 1.13) 
# Pause length: 1.89(0.72,3.21)

#make nice dataframes
#rearrange
df_informed_wide <- d_informed_wide[,c(1,2,3,4,11,12,5,13,7,10,6,8,9)] 
#rename column
df_informed_wide <- df_informed_wide%>% 
  rename('PitchMode'='v1') %>% 
  rename('PitchVar'='v2') %>% 
  rename('SpeechRate'='v3') %>% 
  rename('ProSpoTime'='v4') %>% 
  rename('NumPause'='v5') %>% 
  rename('LenPause'='v6') %>% 
  rename('Noise1'='v7') %>% 
  rename('Noise2'='v8') %>% 
  rename('Noise3'='v9') %>% 
  rename('Noise4'='v10')
#rename varialbes
d_informed$Variable[d_informed$Variable=='v1'] <- 'PitchMode'
d_informed$Variable[d_informed$Variable=='v2'] <- 'PitchVar'
d_informed$Variable[d_informed$Variable=='v3'] <- 'SpeechRate'
d_informed$Variable[d_informed$Variable=='v4'] <- 'ProSpotime'
d_informed$Variable[d_informed$Variable=='v5'] <- 'NumPause'
d_informed$Variable[d_informed$Variable=='v6'] <- 'LenPause'
d_informed$Variable[d_informed$Variable=='v7'] <- 'Noise1'
d_informed$Variable[d_informed$Variable=='v8'] <- 'Noise2'
d_informed$Variable[d_informed$Variable=='v9'] <- 'Noise3'
d_informed$Variable[d_informed$Variable=='v10'] <- 'Noise4'

#Same goes for skeptical
df_skeptic_wide <- d_skeptic_wide[,c(1,2,3,4,11,12,5,13,7,10,6,8,9)] 
df_skeptic_wide <- df_skeptic_wide%>% 
  rename('PitchMode'='v1') %>% 
  rename('PitchVar'='v2') %>% 
  rename('SpeechRate'='v3') %>% 
  rename('ProSpoTime'='v4') %>% 
  rename('NumPause'='v5') %>% 
  rename('LenPause'='v6') %>% 
  rename('Noise1'='v7') %>% 
  rename('Noise2'='v8') %>% 
  rename('Noise3'='v9') %>% 
  rename('Noise4'='v10')

#d_skeptic
d_skeptic$Variable[d_skeptic$Variable=='v1'] <- 'PitchMode'
d_skeptic$Variable[d_skeptic$Variable=='v2'] <- 'PitchVar'
d_skeptic$Variable[d_skeptic$Variable=='v3'] <- 'SpeechRate'
d_skeptic$Variable[d_skeptic$Variable=='v4'] <- 'ProSpotime'
d_skeptic$Variable[d_skeptic$Variable=='v5'] <- 'NumPause'
d_skeptic$Variable[d_skeptic$Variable=='v6'] <- 'LenPause'
d_skeptic$Variable[d_skeptic$Variable=='v7'] <- 'Noise1'
d_skeptic$Variable[d_skeptic$Variable=='v8'] <- 'Noise2'
d_skeptic$Variable[d_skeptic$Variable=='v9'] <- 'Noise3'
d_skeptic$Variable[d_skeptic$Variable=='v10'] <- 'Noise4'

```

```{r}
MA <- ggplot(aes(x= measurement, color= Group, fill=Group),data=d_informed)+
  geom_density(alpha=0.5)+
  facet_wrap(~Variable)+
  xlab('Measurement')+
  ylab('Density')+
  ggtitle('Informed data')+
  theme_bw()

Noise <- ggplot(aes(x= measurement, color= Group, fill=Group),data=d_skeptic)+
  geom_density(alpha=0.5)+
  facet_wrap(~Variable)+
  xlab('Measurement')+
  ylab('Density')+
  ggtitle('Skeptic data')+
  theme_bw()

sim_data <- grid.arrange(MA,Noise)
ggsave("simulated data.png",sim_data,height=10,width=10,units="in")
```

## Part II - ML pipeline on simulated data
On the two simulated datasets (separately) build a machine learning pipeline: i) create a data budget (e.g. balanced training and test sets); ii) pre-process the data (e.g. scaling the features); iii) fit and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression); iv) assess performance on the test set; v) discuss whether performance is as expected and feature importance is as expected.
Bonus question: replace the bayesian multilevel regression with a different algorithm, e.g. SVM or random forest (but really, anything you'd like to try).

# on the training do hierchacal model, because of multiple ID's

i) create a data budget (e.g. balanced training and test sets)
```{r data budgeting}
TestID <- sample(seq(SampleSize),20)

#MA
train_informed <- df_informed_wide %>%
  subset(!(ID %in% TestID))

test_informed <- df_informed_wide %>%
  subset(ID %in% TestID)

#Noise
train_skeptic <- df_skeptic_wide %>%
  subset(!(ID %in% TestID))

test_skeptic <- df_skeptic_wide %>%
  subset(ID %in% TestID)
```

ii) pre-process the data (e.g. scaling the features);

```{r tidymodel}
library(tidymodels)


#MA
rec_informed <- train_informed %>%
  recipe(Group ~ . ) %>% # defines the outcome        
  step_scale('PitchVar','SpeechRate','ProSpoTime','NumPause','LenPause','Noise1','Noise2','Noise3','Noise4' ) %>% # scales numeric predictors
  step_center('PitchVar','SpeechRate','ProSpoTime','NumPause','LenPause','Noise1','Noise2','Noise3','Noise4') %>% # center numeric predictors
  prep(training = train_informed, retain = TRUE)

# recioe(Condition ~.) %>%  update_role(Id, Trial, new_role = "second_level) %>% step_scale(all.numveric()) %>% set_center(all.numeric()) %>% prep(training=train_data,retain=T)


#Noise
rec_skeptic <- train_skeptic %>%
  recipe(Group ~ . ) %>% # defines the outcome        
  step_scale('PitchVar','SpeechRate','ProSpoTime','NumPause','LenPause','Noise1','Noise2','Noise3','Noise4') %>% # scales numeric predictors
  step_center('PitchVar','SpeechRate','ProSpoTime','NumPause','LenPause','Noise1','Noise2','Noise3','Noise4') %>% # center numeric predictors
  prep(training = train_skeptic, retain = TRUE)


#Apply recipe to train and test
##MA
train_informed_s <- juice(rec_informed)
test_informed_s <- bake(rec_informed, new_data = test_informed, all_predictors()) %>% 
  mutate(Group = test_informed$Group)
##Noise
train_skeptic_s <- juice(rec_skeptic)
test_skeptic_s <- bake(rec_skeptic, new_data = test_skeptic, all_predictors()) %>% 
  mutate(Group = test_skeptic$Group)

```


iii) fit and assess a classification algorithm on the training data (e.g. Bayesian multilevel logistic regression); 
#come back to
```{r make model}
class_model <- bf(Group ~ 1 + PitchVar+SpeechRate+ProSpoTime+NumPause+LenPause+Noise1+Noise2+Noise3+Noise4 + (1 + PitchVar + SpeechRate + ProSpoTime  + NumPause  + LenPause  + Noise1  + Noise2  + Noise3  + Noise4 | ID))

class_model_intercept <- bf(Group ~ 1 + PitchVar+SpeechRate+ProSpoTime+NumPause+LenPause+Noise1+Noise2+Noise3+Noise4 + (1 | ID))

class_model_ground <-  bf(Group ~ 1 + PitchVar+SpeechRate+ProSpoTime+NumPause+LenPause+Noise1+Noise2+Noise3+Noise4 )
```

```{r prior}
get_prior(class_model,data=train_informed_s,family = bernoulli)

p1 <- c(
  prior(normal(0,1),class=b),
  prior(normal(0,0.3),class=sd),
  prior(normal(0,0.2),class=sd,group=ID),
  # prior(normal(0,0.2),class=cor),
  # prior(normal(0,0.1),class=cor, group=ID)
  prior(lkj(1), class= "cor"),
  prior(lkj(1),class=cor,group=ID)
)
```

```{r fit prior}
#MA
class_model_p1 <- 
  brm(
    class_model, 
    data = train_informed_s,
    family = bernoulli,
    prior = p1,  
    sample_prior = "only", 
    iter = 2000, #at least 4000 iters
    warmup = 1000,#at least 400
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,#more cores, more parallel processing
    chains = 2, #at least two chains, use 4
    file = "class_model_p1",
    control = list(adapt_delta = 0.99, max_treedepth = 20))

#Noise
class_model_p1_noise <- 
  brm(
    class_model, 
    data = train_skeptic_s,
    family = bernoulli,
    prior = p1,  
    sample_prior = "only", 
    iter = 2000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "class_model_p1_noise",
    control = list(adapt_delta = 0.99, max_treedepth = 20))
```

```{r prior check}
#pp checking the priors - could look better, but fine i guess
pp <- pp_check(class_model_p1, ndraws = 100)+labs(title='Train Informed')
ggsave('prior check model.png',pp)

pp_noise <- pp_check(class_model_p1_noise, ndaws=100)+labs(title='Train Skeptic')
```

```{r fit model}
class_fit_p1 <- 
  brm(
    class_model, 
    data = train_informed_s,
    family = bernoulli,
    prior = p1,  
    sample_prior = T, 
    save_pars = save_pars(all = TRUE),
    #refit = "on_change",
    iter = 2000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "class_fit_p1",
    control = list(adapt_delta = 0.99, max_treedepth = 20),
    stan_model_args=list(stanc_options = list("O1"))
    )

#Noise
class_fit_p1_noise <- 
  brm(
    class_model, 
    data = train_skeptic_s,
    family = bernoulli,
    prior = p1,  
    sample_prior = T, 
    save_pars = save_pars(all = TRUE),
    #refit = "on_change",
    iter = 2000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    file = "class_fit_p1_noise",
    control = list(adapt_delta = 0.99, max_treedepth = 20),
    stan_model_args=list(stanc_options = list("O1"))
    )
```

```{r update models with fit}
es1p1upd <- update(class_fit_p1)
pu1p1upd <- update(es1p1fit,newdata=subset(d,Published==1))


```

```{r posterior check}
pop <- pp_check(class_fit_p1, ndraws = 100)+labs(title='Train Informed')+xlim(-1,3)
pop_noise <- pp_check(class_fit_p1_noise, ndraws=100)+labs(title='Train Skeptic')
grid.arrange(pop,pop_noise)

```
```{r prior posterior plots informed}
#Model 1 fitted
# variables(class_fit_p1)
# #Sample the parameters of interest:
# Posterior_all <- as_draws_df(class_fit_p1)
# prior_informed <- as_draws_df(class_model_p1)
  
#   [1] "b_Intercept"                    "b_PitchVar"                    
#    [3] "b_SpeechRate"                   "b_ProSpoTime"                  
#    [5] "b_NumPause"                     "b_LenPause"                    
#    [7] "b_Noise1"                       "b_Noise2"                      
#    [9] "b_Noise3"                       "b_Noise4" 
# "Intercept" 
#  [869] "prior_sd_ID"                    "prior_cor_ID"                  
#  [871] "lprior"                         "lp__" 


intercept <-
  ggplot()+
  geom_density(aes(Posterior_all$b_Intercept),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes(prior_informed$b_Intercept),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
      ylim(0,3)+

  xlab('Estimate')+
  ggtitle('Intercept')

pitchvar <-  
  ggplot()+
  geom_density(aes(Posterior_all$b_PitchVar),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_informed$b_PitchVar),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab('Estimate')+
      ylim(0,3)+
  ggtitle('Pitch Variability')

speechrate <-  
  ggplot()+
  geom_density(aes(Posterior_all$b_SpeechRate),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_informed$b_SpeechRate),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab('Estimate')+
      ylim(0,3)+
  ggtitle('Speech Rate')

prospotime <-  
  ggplot()+
  geom_density(aes(Posterior_all$b_ProSpoTime),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_informed$b_ProSpoTime),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+  
  xlim(-4,5)+
    xlab('Estimate')+
      ylim(0,3)+
  ggtitle('Proportion of Speech time')

numpause <-  
  ggplot()+
  geom_density(aes(Posterior_all$b_NumPause),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_informed$b_NumPause),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab('Estimate')+
      ylim(0,3)+
  ggtitle('Number of Pauses')

lenpause <-  
  ggplot()+
  geom_density(aes(Posterior_all$b_LenPause),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_informed$b_LenPause),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab('Estimate')+
      ylim(0,3)+
  ggtitle('Length of Pauses')

noise1 <-  
  ggplot()+
  geom_density(aes(Posterior_all$b_Noise1),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_informed$b_Noise1),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab('Estimate')+
      ylim(0,3)+
    ggtitle('Noise1')

noise2 <-  
  ggplot()+
  geom_density(aes(Posterior_all$b_Noise2),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_informed$b_Noise2),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab('Estimate')+
      ylim(0,3)+
  ggtitle('Noise2')

noise3 <-  
  ggplot()+
  geom_density(aes(Posterior_all$b_Noise3),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_informed$b_Noise3),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab('Estimate')+
      ylim(0,3)+
  ggtitle('Noise3')

noise4 <-  
  ggplot()+
  geom_density(aes(Posterior_all$b_Noise4),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_informed$b_Noise4),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
  xlim(-4,5)+
    xlab('Estimate')+
        ylim(0,3)+

  ggtitle('Noise4')


pop_informed <- grid.arrange(intercept, pitchvar, speechrate, prospotime, numpause, lenpause, noise1, noise2, noise3, noise4, top='Prior-posterior Informed',ncol=4)
```

```{r prior posterior plots noise}
#Model 1 fitted
# variables(class_fit_p1_noise)
# #Sample the parameters of interest:
 posterior_skeptic <- as_draws_df(class_fit_p1_noise)
 prior_skeptic <- as_draws_df(class_model_p1_noise)
  



intercept_n <-
  ggplot()+
  geom_density(aes(posterior_skeptic$b_Intercept),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes(prior_skeptic$b_Intercept),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
  xlim(-4,5)+
  ylim(0,3)+
  ylab('Density')+
  xlab(NULL)+
  ggtitle('Intercept')

pitchvar_n <-  
  ggplot()+
  geom_density(aes(posterior_skeptic$b_PitchVar),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_skeptic$b_PitchVar),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab(NULL)+
      ylab(NULL)+

      ylim(0,3)+
  ggtitle('Pitch Variability')

speechrate_n <-  
  ggplot()+
  geom_density(aes(posterior_skeptic$b_SpeechRate),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_skeptic$b_SpeechRate),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab(NULL)+
      ylim(0,3)+
      ylab(NULL)+

  ggtitle('Speech Rate')

prospotime_n <-  
  ggplot()+
  geom_density(aes(posterior_skeptic$b_ProSpoTime),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_skeptic$b_ProSpoTime),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+  
  xlim(-4,5)+
    xlab(NULL)+
      ylim(0,3)+
      ylab(NULL)+

  ggtitle('Proportion of Speech time')

numpause_n <-  
  ggplot()+
  geom_density(aes(posterior_skeptic$b_NumPause),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_skeptic$b_NumPause),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab(NULL)+
  ylab('Density')+
      ylim(0,3)+
  ggtitle('Number of Pauses')

lenpause_n <-  
  ggplot()+
  geom_density(aes(posterior_skeptic$b_LenPause),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_skeptic$b_LenPause),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab(NULL)+
      ylim(0,3)+
      ylab(NULL)+

  ggtitle('Length of Pauses')

noise1_n <-  
  ggplot()+
  geom_density(aes(posterior_skeptic$b_Noise1),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_skeptic$b_Noise1),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab('Estimate')+
      ylim(0,3)+
      ylab(NULL)+

    ggtitle('Noise1')

noise2_n <-  
  ggplot()+
  geom_density(aes(posterior_skeptic$b_Noise2),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_skeptic$b_Noise2),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab('Estimate')+
      ylim(0,3)+
    ylab(NULL)+

  ggtitle('Noise2')

noise3_n <-  
  ggplot()+
  geom_density(aes(posterior_skeptic$b_Noise3),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_skeptic$b_Noise3),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
    xlim(-4,5)+
    xlab('Estimate')+
  ylab('Density')+
      ylim(0,3)+
  ggtitle('Noise3')

noise4_n <-  
  ggplot()+
  geom_density(aes(posterior_skeptic$b_Noise4),
                   fill='green',
                   color='green',
                   alpha=0.3
                   )+
  geom_density(aes( prior_skeptic$b_Noise4),
                   fill='red',
                   color='red',
                   alpha=0.3
                   )+
  xlim(-4,5)+
    xlab('Estimate')+
        ylim(0,3)+
  ylab(NULL)+
  ggtitle('Noise4')




pop_skeptic <- grid.arrange(intercept_n, pitchvar_n, speechrate_n, prospotime_n, numpause_n, lenpause_n, noise1_n, noise2_n, noise3_n, noise4_n, top='Prior-posterior Skeptic',ncol=4)
ggsave('update plots skeptic.png',pop_skeptic,height=10,width=10,units="in")
```

```{r extra plots, not needed}
pacman::p_load(devtools)
devtools::install_github("JosephCrispell/basicPlotteR")
library(basicPlotteR)
distributions <- list(prior_informed[,1], 
                      prior_informed[,2], 
                      prior_informed[,3],
                      prior_informed[,4],
                      prior_informed[,5],
                      prior_informed[,6],
                      prior_informed[,7],
                      prior_informed[,8],
                      prior_informed[,9],
                      prior_informed[,10])

# Plot overlapping histograms
basicPlotteR::plotMultipleHistograms(distributions, #nBins=20, 
                       colours=c("red","green", "blue","orange","black","grey","pink","yellow","cyan","chocolate"), 
                       las=1, main="Prior Informed", xlab="Estimate")
legend('topright', c("PitchVar", "SpeechRate", "ProSpoTime", "NumPause","LenPause","Noise1","Noise2","Noise3","Noise4"), fill=c("red","green", "blue","orange","black","grey","pink","yellow","cyan","chocolate"))
title("Prior Informed")

    p_all <- grid.arrange(Intercept, Sigma, InterceptPub, SigmaPub, top='Prior-posterior update check')
    ggsave('pp_update.png',
           p_all,width=17,height=17,units='cm')
  
```
```{r model output}
summary(class_fit_p1)
summary(class_fit_p1_noise)
```

iv) assess performance on the test set;
```{r prediction and performance}
# generate average predictions 
### skeptic
##for the trained dataset
train_skeptic_s$PredictionsPerc0 <- predict(class_fit_p1_noise)[, 1]
train_skeptic_s$Predictions0[train_skeptic_s$PredictionsPerc0 > 0.5] <- "Schizophrenia"
train_skeptic_s$Predictions0[train_skeptic_s$PredictionsPerc0 <= 0.5] <- "Control"

# #vary intercept
# train_skeptic_s$PredictionsPerc1 <- predict(PitchRange_m1)[, 1]
# train_skeptic_s$Predictions1[train_skeptic_s$PredictionsPerc1 > 0.5] <- "Schizophrenia"
# train_skeptic_s$Predictions1[train_skeptic_s$PredictionsPerc1 <= 0.5] <- "Control"
# 
# #vary slopes
# train_skeptic_s$PredictionsPerc2 <- predict(PitchRange_m2)[, 1]
# train_skeptic_s$Predictions2[train_skeptic_s$PredictionsPerc2 > 0.5] <- "Schizophrenia"
# train_skeptic_s$Predictions2[train_skeptic_s$PredictionsPerc2 <= 0.5] <- "Control"


train_skeptic_s <- train_skeptic_s %>% 
  mutate(
    Group = as.factor(Group), 
    Predictions0 = as.factor(Predictions0)#,
    #Predictions1 = as.factor(Predictions1),
    #Predictions2 = as.factor(Predictions2)
  )

train_skeptic_s

### informed
##for the trained dataset
#fixed effect
train_informed_s$PredictionsPerc0 <- predict(class_fit_p1)[, 1]
train_informed_s$Predictions0[train_informed_s$PredictionsPerc0 > 0.5] <- "Schizophrenia"
train_informed_s$Predictions0[train_informed_s$PredictionsPerc0 <= 0.5] <- "Control"

# #vary intercept
# train_informed_s$PredictionsPerc1 <- predict(PitchRange_m1)[, 1]
# train_informed_s$Predictions1[train_informed_s$PredictionsPerc1 > 0.5] <- "Schizophrenia"
# train_informed_s$Predictions1[train_informed_s$PredictionsPerc1 <= 0.5] <- "Control"
# 
# #vary slopes
# train_informed_s$PredictionsPerc2 <- predict(PitchRange_m2)[, 1]
# train_informed_s$Predictions2[train_informed_s$PredictionsPerc2 > 0.5] <- "Schizophrenia"
# train_informed_s$Predictions2[train_informed_s$PredictionsPerc2 <= 0.5] <- "Control"


train_informed_s <- train_informed_s %>% 
  mutate(
    Group = as.factor(Group), 
    Predictions0 = as.factor(Predictions0)#,
    #Predictions1 = as.factor(Predictions1),
    #Predictions2 = as.factor(Predictions2)
  )

train_informed_s
```
```{r prediction for test}
# generate average predictions 
### skeptic
##for the test dataset
test_skeptic_s$PredictionsPerc0 <- predict(class_fit_p1_noise, newdata = test_informed_s, allow_new_levels = TRUE)[, 1]
test_skeptic_s$Predictions0[test_skeptic_s$PredictionsPerc0 > 0.5] <- "Schizophrenia"
test_skeptic_s$Predictions0[test_skeptic_s$PredictionsPerc0 <= 0.5] <- "Control"

# #vary intercept
# train_skeptic_s$PredictionsPerc1 <- predict(PitchRange_m1)[, 1]
# train_skeptic_s$Predictions1[train_skeptic_s$PredictionsPerc1 > 0.5] <- "Schizophrenia"
# train_skeptic_s$Predictions1[train_skeptic_s$PredictionsPerc1 <= 0.5] <- "Control"
# 
# #vary slopes
# train_skeptic_s$PredictionsPerc2 <- predict(PitchRange_m2)[, 1]
# train_skeptic_s$Predictions2[train_skeptic_s$PredictionsPerc2 > 0.5] <- "Schizophrenia"
# train_skeptic_s$Predictions2[train_skeptic_s$PredictionsPerc2 <= 0.5] <- "Control"


test_skeptic_s <- test_skeptic_s %>% 
  mutate(
    Group = as.factor(Group), 
    Predictions0 = as.factor(Predictions0)#,
    #Predictions1 = as.factor(Predictions1),
    #Predictions2 = as.factor(Predictions2)
  )

test_skeptic_s

### informed
##for the tested dataset
#fixed effect
test_informed_s$PredictionsPerc0 <- predict(class_fit_p1, newdata=test_informed_s, allow_new_levels=TRUE)[, 1]
test_informed_s$Predictions0[test_informed_s$PredictionsPerc0 > 0.5] <- "Schizophrenia"
test_informed_s$Predictions0[test_informed_s$PredictionsPerc0 <= 0.5] <- "Control"

# #vary intercept
# train_informed_s$PredictionsPerc1 <- predict(PitchRange_m1)[, 1]
# train_informed_s$Predictions1[train_informed_s$PredictionsPerc1 > 0.5] <- "Schizophrenia"
# train_informed_s$Predictions1[train_informed_s$PredictionsPerc1 <= 0.5] <- "Control"
# 
# #vary slopes
# train_informed_s$PredictionsPerc2 <- predict(PitchRange_m2)[, 1]
# train_informed_s$Predictions2[train_informed_s$PredictionsPerc2 > 0.5] <- "Schizophrenia"
# train_informed_s$Predictions2[train_informed_s$PredictionsPerc2 <= 0.5] <- "Control"


test_informed_s <- test_informed_s %>% 
  mutate(
    Group = as.factor(Group), 
    Predictions0 = as.factor(Predictions0)#,
    #Predictions1 = as.factor(Predictions1),
    #Predictions2 = as.factor(Predictions2)
  )

test_informed_s
```
```{r assessing performance}
#train informed
conf_mat(
  train_informed_s,
  truth = Group,
  estimate = Predictions0,
  dnn = c('Prediction','Truth')
)
train_info_pred <-
metrics(train_informed_s,
        truth = Group, estimate = Predictions0) %>% 
  knitr::kable()

#train skeptic
conf_mat(
  train_skeptic_s,
  truth = Group,
  estimate = Predictions0,
  dnn = c('Prediction','Truth')
)
train_skep_pred <-
metrics(train_skeptic_s,
        truth = Group, estimate = Predictions0) %>% 
  knitr::kable()

#test informed
conf_mat(
  test_informed_s,
  truth = Group,
  estimate = Predictions0,
  dnn = c('Prediction','Truth')
)

test_infor_pred <- metrics(test_informed_s,
        truth = Group, estimate = Predictions0) %>% 
  knitr::kable()

#test skeptic
 conf_mat(
  test_skeptic_s,
  truth = Group,
  estimate = Predictions0,
  dnn = c('Prediction','Truth')
)

test_skep_pred <- metrics(test_skeptic_s,
        truth = Group, estimate = Predictions0) %>% 
  knitr::kable()
```

```{r plot the prediction}
labels <- c('data','accuracy','kap')
test_skep_pred_l <- c('test_skeptic',0.375,-0.250)
train_skep_pred_l <- c('train_skeptic',0.375,-0.250)
test_infor_pred_l <- c('test_informed',0.945,0.890) 
test_skep_pred_l <- c('test_skeptic', 0.375,-0.250)
train_info_pred_l <-  c('train_informed',0.984,0.969)

prediction_accuracy <- as.data.frame( rbind(train_info_pred_l,test_infor_pred_l,train_skep_pred_l,test_skep_pred_l))
prediction_accuracy <- prediction_accuracy %>% 
  rename('data'='V1') %>% 
  rename('accuracy'='V2') %>% 
  rename('kap'='V3')
prediction_accuracy <- reshape2::melt(prediction_accuracy, id.vars='data')

prediction_plot <- prediction_accuracy %>% 
  ggplot(aes(y=value,x=data,color=variable, fill=variable))+
  geom_point()+
  ggtitle('Average prediction')
ggsave('average prediction plot.png',prediction_plot)
  

```
```{r prediction uncertainty}
PerformanceProb <- tibble(expand_grid(
  Sample=seq(2000), # remember this is from brm(iter=XX), sample=seq(XX)
  Model=c('VaryingIntercept_Slope'), #add more coloumns, if you have more models
  Setup = c('Informed','Skeptic'),
  Type = c('Training', 'Test'),
  Accuracy = NULL
))

#Informed

train0 <- inv_logit_scaled(posterior_linpred(class_fit_p1,summary=F))
test0 <- inv_logit_scaled(posterior_linpred(class_fit_p1, summary=F, newdata=test_informed_s, allow_new_levels=T))


for (i in seq(2000)){
  train_informed_s$Predictions0 <- as.factor(ifelse(train0[i,]>0.5, "Schizophrenia","Control"))
   test_informed_s$Predictions0 <- as.factor(ifelse(test0[i,]>0.5, "Schizophrenia","Control"))
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VaryingIntercept_Slope" & PerformanceProb$Setup == 'Informed' & PerformanceProb$Type == "Training"] <- accuracy(train_informed_s, truth=Group, estimate=Predictions0)[,'.estimate']
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VaryingIntercept_Slope" & PerformanceProb$Setup == 'Informed' & PerformanceProb$Type == "Test"] <- accuracy(test_informed_s, truth=Group, estimate = Predictions0)[,'.estimate']
  
    PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VaryingIntercept_Slope" & PerformanceProb$Setup == 'Skeptic' & PerformanceProb$Type == "Training"] <- accuracy(train_informed_s, truth=Group, estimate=Predictions0)[,'.estimate']
  
  PerformanceProb$Accuracy[PerformanceProb$Sample == i & PerformanceProb$Model == "VaryingIntercept_Slope" & PerformanceProb$Setup == 'Skeptic' & PerformanceProb$Type == "Test"] <- accuracy(test_informed_s, truth=Group, estimate = Predictions0)[,'.estimate']
}

```
#Error in train[i,]: subscript out of bounds

v) discuss whether performance is as expected and feature importance is as expected.
```{r feature importance}
pacman::p_load(DALEX,DALEXtra,kernlab,xgboost,knitr,dotwhisker)

d_inf <- train_informed_s_fea %>% 
  mutate(ID=NULL, Trial=NULL,Preds=NULL,Predictions=NULL,v1_s=NULL)
  d_inf$Group <- as.factor(train_informed_s$Group)

LogisticRegression_inf <- logistic_reg() %>% 
  set_mode('classification') %>% 
  set_engine('glm') %>% 
  fit(Group ~ ., data=d_inf)

train_informed_s_fea <- subset(train_informed_s, select=-c(PredictionsPerc0,Predictions0))

explainer_lm <- 
  explain_tidymodels(
    LogisticRegression_inf,
    data=train_informed_s_fea,
    y = as.numeric(train_informed_s_fea$Group) - 1,
    label = 'logReg',
    verbose = FALSE
  )

exp_lm <- explainer_lm %>% 
  model_parts() %>% 
  plot(show_boxplots = FALSE) + ggtitle('Feature Importance', '')

ggsave('feature_selection.png',exp_lm)
```

## Part III - Applying the ML pipeline to empirical data
Download the empirical dataset from brightspace and apply your ML pipeline to the new data, adjusting where needed. Warning: in the simulated dataset we only had 10 features, now you have many more! Such is the life of the ML practitioner. Consider the impact a higher number of features will have on your ML inference, and decide whether you need to cut down the number of features before running the pipeline (or alternatively expand the pipeline to add feature selection).
Data: https://www.dropbox.com/s/7ky1axvea33lgye/Ass3_empiricalData1.csv?dl=0

#Look at week 11 slides
```{r}
df <- read.csv("Ass3_empiricalData1.csv")

glimpse(df)

#remember when data budgetting to be carefull not to just take 20%, as the distribution og age,gender and other biases should be equally distributed in the test and training data
```

